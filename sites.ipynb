{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass\n",
    "import warnings\n",
    "import spacy\n",
    "from typing import Protocol\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from typing import Type\n",
    "from typing import Type\n",
    "from functools import lru_cache\n",
    "\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.options.display.max_columns = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MeLiClient:\n",
    "    site: str\n",
    "\n",
    "    def get_categories(self) -> pd.DataFrame:\n",
    "        url = f\"https://api.mercadolibre.com/sites/{self.site}/categories\"\n",
    "        return pd.DataFrame(requests.get(url).json())\n",
    "\n",
    "    def get_items_in_category(self, category_id: str, offset=0) -> pd.DataFrame:\n",
    "\n",
    "        url = f\"https://api.mercadolibre.com/sites/{self.site}/search?category={category_id}&offset={offset}\"\n",
    "        request = requests.get(url)\n",
    "        items = request.json()\n",
    "        try:\n",
    "            return pd.DataFrame(items[\"results\"])\n",
    "        except Exception:\n",
    "            return pd.DataFrame()\n",
    "\n",
    "    def get_all_items_in_category(self, category_id: str) -> pd.DataFrame:\n",
    "\n",
    "        offset = 0\n",
    "        results = []\n",
    "\n",
    "        result = self.get_items_in_category(category_id)\n",
    "        results.append(result)\n",
    "\n",
    "        while len(result) > 0:\n",
    "            offset += 50\n",
    "\n",
    "            result = self.get_items_in_category(category_id, offset=offset)\n",
    "            results.append(result)\n",
    "\n",
    "        return pd.concat(results)\n",
    "\n",
    "\n",
    "site = \"MCO\"\n",
    "meli = MeLiClient(site)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = meli.get_categories()\n",
    "categories.query(\"id=='MCO1000'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://developers.mercadolibre.com.ar/es_co/atributos\n",
    "# http://www.heikopaulheim.com/docs/swj2018_product_data.pdf\n",
    "\n",
    "# items[items[\"attributes\"].apply(lambda sku: 'DESCRIPTIVE_TAGS' in (x[\"id\"] for x in sku))] # empty\n",
    "# items[items[\"attributes\"].apply(lambda sku: 'PRODUCT_FEATURES' in (x[\"id\"] for x in sku))] # empty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attribute_value(attributes: list, attribute_name: str):\n",
    "    return next(\n",
    "        (x[\"value_name\"] for x in attributes if x[\"id\"] == attribute_name),\n",
    "        None,\n",
    "    )\n",
    "\n",
    "\n",
    "def build_dataset(\n",
    "    meli: MeLiClient,\n",
    "    category_id: str,\n",
    "    features: list[str],\n",
    "    attributes: list[str],\n",
    "    save=True,\n",
    "):\n",
    "\n",
    "    items = meli.get_all_items_in_category(category_id)\n",
    "    df = items[features]\n",
    "\n",
    "    for attribute in attributes:\n",
    "        df[attribute.lower()] = items.attributes.apply(\n",
    "            get_attribute_value, attribute_name=attribute\n",
    "        )\n",
    "\n",
    "    df = df.drop(columns=\"attributes\").dropna(how=\"all\", axis=1).reset_index(drop=True)\n",
    "\n",
    "    if save:\n",
    "        df.to_csv(f\"{category_id}_items.csv\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "FEATURES = [\"id\", \"title\", \"thumbnail\", \"domain_id\", \"attributes\"]\n",
    "INTERESTING_ATTRIBUTES = [\"GTIN\", \"BRAND\", \"MODEL\"]\n",
    "category = \"MCO1000\"  # categories.id.sample().squeeze()\n",
    "print(category)\n",
    "\n",
    "\n",
    "df = build_dataset(meli, category, FEATURES, INTERESTING_ATTRIBUTES)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Preprocessing Utils\n",
    "\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "\n",
    "\n",
    "def preprocessor(text: str):\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    return text.lower().strip()\n",
    "\n",
    "\n",
    "def tokenizer(text: str):\n",
    "    doc = nlp(text)  # probably overkill using spacy for this but ok\n",
    "    tokens = [word.lemma_ for word in doc if not word.is_stop and not word.is_punct]\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(Protocol):\n",
    "    @classmethod\n",
    "    def initialize(cls, corpus: list[str]) -> None:\n",
    "        ...\n",
    "\n",
    "    def similarity(self, other: \"Embedding\") -> float:\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpacyEmbedding:\n",
    "    def __init__(self, text: str):\n",
    "        self.embedding = nlp(text)\n",
    "\n",
    "    @classmethod\n",
    "    def initialize(cls, corpus: list[str]) -> None:\n",
    "        pass\n",
    "\n",
    "    def similarity(self, other: \"SpacyEmbedding\") -> float:\n",
    "        return self.embedding.similarity(other.embedding)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(tuple(self.embedding))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWordsEmbedding:\n",
    "    def __init__(self, text: str):\n",
    "        self.embedding = self.bow.transform([text])[0]\n",
    "        self.tokens = tokenizer(text)\n",
    "\n",
    "    @classmethod\n",
    "    def initialize(cls, corpus: list[str]) -> None:\n",
    "        cls.bow = CountVectorizer(tokenizer=tokenizer, preprocessor=preprocessor).fit(\n",
    "            corpus\n",
    "        )\n",
    "\n",
    "    def similarity(self, other: \"BagOfWordsEmbedding\") -> float:\n",
    "        return cosine_similarity(self.embedding, other.embedding)[0][0]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(tuple(self.tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDFEmbedding:\n",
    "    def __init__(self, text: str):\n",
    "        self.embedding = self.tfidf.transform([text])[0]\n",
    "        self.tokens = tokenizer(text)\n",
    "\n",
    "    @classmethod\n",
    "    def initialize(cls, corpus: list[str]) -> None:\n",
    "        cls.tfidf = TfidfVectorizer(tokenizer=tokenizer, preprocessor=preprocessor).fit(\n",
    "            corpus\n",
    "        )\n",
    "\n",
    "    def similarity(self, other: \"TFIDFEmbedding\") -> float:\n",
    "        return cosine_similarity(self.embedding, other.embedding)[0][0]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return str(tuple(self.tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_embeddings(df, embedding_type: Type[Embedding], embedding_cols: tuple[str]):\n",
    "\n",
    "    embedding_type.initialize(df.title)\n",
    "    for col in embedding_cols:\n",
    "        df[f\"{col}_embedding\"] = df[col].apply(embedding_type)\n",
    "    return df\n",
    "\n",
    "\n",
    "EMBEDDING_COLS = (\"title\",)  # , \"brand\", \"model\"]\n",
    "df = find_embeddings(df, BagOfWordsEmbedding, EMBEDDING_COLS)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similarities(\n",
    "    df: pd.DataFrame, embedding: Embedding, feature=\"title_embedding\"\n",
    "):\n",
    "    similarities = df[feature].apply(embedding.similarity)\n",
    "    return similarities\n",
    "\n",
    "\n",
    "find_similarities(df, df.title_embedding.iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_exact_match(df: pd.DataFrame, feature: str, feature_value):\n",
    "    return df[feature] == feature_value\n",
    "\n",
    "\n",
    "feature_exact_match(df, \"brand\", \"Hill's\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_products(\n",
    "    df: pd.DataFrame,\n",
    "    product_id: str,\n",
    "    embedding_feature=\"title_embedding\",\n",
    "    penalty_features=[\"brand\", \"domain_id\"],\n",
    "    penalty_value=0.1,\n",
    "    threshold=0.7,\n",
    "):\n",
    "    details = df.copy()\n",
    "    product = df.set_index(\"id\").loc[product_id]\n",
    "    details[\"similarity\"] = find_similarities(\n",
    "        df, product[embedding_feature], embedding_feature\n",
    "    )\n",
    "    details[\"raw_similarity\"] = details.similarity.copy()\n",
    "\n",
    "    for penalty_feature in penalty_features:\n",
    "        is_exact_match = feature_exact_match(\n",
    "            df, penalty_feature, product[penalty_feature]\n",
    "        )\n",
    "        details[f\"{penalty_feature}_penalty\"] = (\n",
    "            ~is_exact_match * penalty_value if pd.notna(product[penalty_feature]) else 0\n",
    "        )\n",
    "        details[\"similarity\"] -= details[f\"{penalty_feature}_penalty\"]\n",
    "\n",
    "    products_above_threshold = details[details[\"similarity\"] > threshold]\n",
    "    similar_products = details.loc[products_above_threshold.index]\n",
    "    return similar_products, details\n",
    "\n",
    "\n",
    "PENALTY_FEATURES = (\"brand\", \"domain_id\", \"model\")\n",
    "find_similar_products(df, \"MCO618049088\", penalty_features=PENALTY_FEATURES)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_dataset(filename: str):\n",
    "    test_data = pd.read_excel(filename, sheet_name=[\"test_set\", \"all\"])\n",
    "    test_set, all = test_data[\"test_set\"], test_data[\"all\"]\n",
    "    return test_set, all\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class SimilarityConfig:\n",
    "    test_filename: str\n",
    "    embedding_type: Type[Embedding]\n",
    "    embedding_feature: str\n",
    "    penalty_features: tuple[str]\n",
    "    penalty_value: float\n",
    "    threshold: float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SimilarityConfig(\n",
    "    test_filename=\"test_electronica.xlsx\",\n",
    "    embedding_type=BagOfWordsEmbedding,\n",
    "    embedding_feature=\"title\",\n",
    "    penalty_features=PENALTY_FEATURES,\n",
    "    penalty_value=0.05,\n",
    "    threshold=0.7,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache(16)\n",
    "def build_testing_data(config: SimilarityConfig):\n",
    "    test_set, df = load_test_dataset(config.test_filename)\n",
    "    data = find_embeddings(df, config.embedding_type, [config.embedding_feature])\n",
    "    return test_set, data\n",
    "\n",
    "\n",
    "test_set, data = build_testing_data(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_product_matches(\n",
    "    df: pd.DataFrame, product_id: str, cfg: SimilarityConfig, true_matches: list[str]\n",
    "):\n",
    "    matches, details = find_similar_products(\n",
    "        df,\n",
    "        product_id,\n",
    "        penalty_features=cfg.penalty_features,\n",
    "        embedding_feature=cfg.embedding_feature + \"_embedding\",\n",
    "        penalty_value=cfg.penalty_value,\n",
    "        threshold=cfg.threshold,\n",
    "    )\n",
    "\n",
    "    tp = matches[matches.id.isin(true_matches)]\n",
    "    fp = matches[~matches.id.isin(true_matches)]\n",
    "    fn = df[(df.id.isin(true_matches) & (~df.id.isin(matches.id)))]\n",
    "    tn = df[(~df.id.isin(true_matches) & (~df.id.isin(matches.id)))]\n",
    "\n",
    "    return tp, fp, fn, tn\n",
    "\n",
    "\n",
    "test_id = test_set.test_id.iloc[0]\n",
    "tm = test_set[test_set.test_id == test_id].id\n",
    "test_product_matches(data, test_id, config, tm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_and_recall(\n",
    "    true_positives: pd.DataFrame,\n",
    "    false_positives: pd.DataFrame,\n",
    "    false_negatives: pd.DataFrame,\n",
    "    true_negatives: pd.DataFrame,\n",
    "):\n",
    "    tp, fp, fn, tn = (\n",
    "        len(true_positives),\n",
    "        len(false_positives),\n",
    "        len(false_negatives),\n",
    "        len(true_negatives),\n",
    "    )\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn)\n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "get_precision_and_recall(*test_product_matches(data, test_id, config, tm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_similarity_model(cfg: SimilarityConfig):\n",
    "    print(\"building testing data...\")\n",
    "    test_set, data = build_testing_data(cfg.test_filename, config)\n",
    "    test_products = test_set.test_id.unique()\n",
    "    all_cf = []\n",
    "\n",
    "    print(\"finding similar products...\")\n",
    "    for product_id in test_products:\n",
    "        print(f\"\\ntesting {product_id}\")\n",
    "        true_matches = test_set[test_set.test_id == product_id].id\n",
    "        confusion_matrix = test_product_matches(data, product_id, cfg, true_matches)\n",
    "        precision, recall = get_precision_and_recall(*confusion_matrix)\n",
    "        print(f\"{precision=}\")\n",
    "        print(f\"{recall=}\")\n",
    "\n",
    "        all_cf.append(confusion_matrix)\n",
    "\n",
    "    print(\"finished\\n\")\n",
    "\n",
    "    global_confusion_matrix = [pd.concat(df) for df in zip(*all_cf)]\n",
    "    global_precision, global_recall = get_precision_and_recall(*global_confusion_matrix)\n",
    "    print(f\"{global_precision=}\")\n",
    "    print(f\"{global_recall=}\")\n",
    "\n",
    "    return global_precision, global_recall\n",
    "\n",
    "\n",
    "config = SimilarityConfig(\n",
    "    embedding_type=BagOfWordsEmbedding,\n",
    "    embedding_feature=\"title\",\n",
    "    penalty_features=PENALTY_FEATURES,\n",
    "    penalty_value=0.15,\n",
    "    threshold=0.7,\n",
    ")\n",
    "test_similarity_model(\"test_electronica.xlsx\", config)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f29c12a87c61eb6383010587911db04c5d869ed386a3efbb909b3787da0f0d05"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
